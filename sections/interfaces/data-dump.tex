\section{Data dump}
\label{sec:data-dump}
De eerste bron om te controleren wordt gebruikt als baseline. Dit is de ``data dump''. Dit is een gewoon bestand in RDF formaat dat door de \textit{query engine} opgehaald (lees gedownload) wordt. Vervolgens wordt door de \textit{query engine} gecontroleerd of het effectief wel een bestandsbron is. Eenmaal dit voldaan is, worden steeds de kleinste patronen gezocht die voldoen aan de bron. Dit is nodig omdat de \textit{query engine} zo op de meest performante manier de \textit{joins} kan uitvoeren. Zo kan ten slotte de filter-functie de overbodige oplossingen weghalen. Deze filter-functie is voorzien door GeoSPARQL. Bovendien voorziet Comunica functionaliteiten om data-entiteiten uit de databron te extraheren, wat hier gebeurt op de client. Over deze entiteiten moet een filter functie geÃ«valueerd kunnen worden. Hierdoor is het mogelijk om data dumps te queryen met GeoSPARQL. Aangezien data dumps letterlijk bestanden zijn zonder een eigen voorziening van logica, is het triviaal dat dit afgehandeld moet kunnen worden. De data dump wordt daarom de \textit{baseline} van dit onderzoek, waarbij er gepoogd wordt om dezelfde resultaten bij andere bronnen ook te behalen.

Bij het testen van de data dump worden de GitHub Gist bestanden (zie \sectionref{sec:testset}) rechtstreeks gebruikt. Hier is geen enkel ander programma dat als aanspreekpunt gebruikt wordt. Hierbij is dus ook duidelijk dat het beschreven proces van hierboven correct doorlopen is. Dit is bovendien de manier van werken die gebruikt is bij het maken en controleren van de implementatie.