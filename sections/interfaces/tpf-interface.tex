\section{Triple pattern fragment interface}
\label{sec:impl_tpf_interface}
De volgende bron is de ``triple pattern fragment interface''. Deze server staat tussen de op te vragen bestanden (dus de effectieve gegevens) en de client. Deze server zal ervoor zorgen dat het niet langer nodig is om alle data op te halen, maar in de plaats zal de server de SPARQL query splitsen in verschillende triple pattern fragment requests. Deze vragen alle triples die voldoen aan een enkel tripple pattern fragment en \textit{joinen} dan de resultaten op de client. De filtering gebeurt daarna ook op de client.

Net zoals bij de data dump (zie \sectionref{sec:data-dump}) vraagt de \textit{query engine} de bron op. Hierbij zal hij de bron identificeren als een ``qpf source'', wat staat voor ``Quad pattern fragment''. Dit is eigenlijk de \textit{triple pattern fragment} met hierbij een extra veld (graph) toegevoegd, maar hier wordt niet verder op in gegaan. Vervolgens begint de \textit{query engine} de query op de splitsen in \acrfull{tpf} queries, zodat deze \acrshort{tpf} queries geoptimaliseerd kunnen worden in een volgorde die gebaseerd is op de initiële count query. Hierna worden deze één voor één uitgevoerd. Hij zal vervolgens de kleinste patronen opvragen, zodat de correcte informatie opgevraagd kan worden, met hierbij een minimale hoeveelheid aan overbodige informatie. Dit is enkel mogelijk dankzij de \acrshort{tpf} interface. Dankzij deze manier van werken kan wederom de uiteindelijke filtering van de \textit{queries} louter op de client-side gebeuren.

Voor het opzetten van deze test is gebruik gemaakt van de ``Linked Data Fragments Server''. Deze bouwt een \acrshort{tpf} interface op boven een set van bronbestanden, waarvoor opnieuw de bestanden van GitHub Gist gebruikt zijn, net zoals bij de data dump. Op deze manier is ook verzekerd dat er met dezelfde gegevens gewerkt wordt. 

Als kleine opmerking kan nog vermeld worden dat een \acrshort{tpf} interface gebruikt wordt voor twee redenen. Ten eerste hoeft de client zo niet alle data te downloaden, maar kan de server slechts een fragment (vandaar de naam, deze komt eigenlijk van ``Linked Data Fragments'') van deze data teruggeven. De tweede reden is dat deze filtering meestal (= niet in alle gevallen) zorgt voor een verbeterde performantie. Bij het testen was dit echter niet terug te vinden. Zo blijkt het uitvoeren van de queries met de data dump sneller te gaan dan met de \acrshort{tpf} interface. Hier is echter een logische verklaring voor. De datasets die gebruikt zijn, zijn relatief gezien kleine datasets. Bovendien bevatten deze enkel de noodzakelijke gegevens, waardoor de dataset volledig nodig is voor het uitvoeren van de query. Hierdoor kan er niet genoten worden van de voordelen van de \acrshort{tpf} interface, maar wordt enkel de extra \textit{overhead} waargenomen. Dit gaat echter buiten de \textit{scope} van deze masterproef, daarom werd hier verder geen onderzoek naar gedaan, noch benchmarking van de performantie. Dit is eerder een opmerking bij de ondervindingen.